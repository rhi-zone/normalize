# Moss Philosophy

This document contains the design philosophy and architectural overview for Moss.
For behavioral rules and conventions, see `CLAUDE.md`.

## Project Overview

Moss is tooling orchestration with structural awareness. It implements a "Compiled Context" approach that prioritizes architectural awareness (AST-based understanding) over raw text processing, with verification loops ensuring correctness before output.

## Architecture

Core components:
- **Event Bus**: Async communication (`UserMessage`, `PlanGenerated`, `ToolCall`, `ValidationFailed`, `ShadowCommit`)
- **Context Host**: Manages View Providers (Skeleton, CFG, Dependency Graph) - delegates to plugins
- **Structural Editor**: AST-based editing with fuzzy anchor matching
- **Policy Engine**: Enforces safety rules (velocity checks, quarantine)
- **Validator**: Domain-specific verification loop (compiler, linter, tests)
- **Shadow Git**: Atomic commits per tool call, rollback via git reset

Data flow: User Request → Config Engine → Planner → Context Host (Views) → Draft → Shadow Git → Validator → (retry loop if error) → Commit Handle

Multi-agent model: Ticket-based (not shared chat history). Agents are isolated microservices passing Handles, not context.

See `docs/spec.md` for the full specification.

## Design Tenets

### Minimize LLM Usage

LLM calls are expensive (cost) and slow (latency). Design everything to reduce them:
- Structural tools first: Use AST, grep, validation - not LLM - for deterministic tasks
- LLM only for judgment: Generation, decisions, ambiguity resolution
- Measure separately: Track LLM calls vs tool calls in benchmarks
- Cache aggressively: Same query → same answer (where applicable)

This is why we have skeleton views (understand code without LLM), validation loops (catch errors without LLM), and DWIM (find tools without LLM). The goal: an agent that calls the LLM 10x less than naive approaches.

### Prompt Engineering for Token Efficiency

When you do call an LLM, minimize output tokens. Our system prompt in `src/moss/agent_loop.py` explicitly forbids:
- Preamble and summary
- Markdown formatting (bold, headers, code blocks unless asked)
- More than 5 bullet points for analysis

Result: 12x reduction in output tokens (1421 → 112) with same quality insights.

### Hyper-Modular Architecture

Prefer many small, focused modules over fewer large ones:
- Maintainability: Easier to understand, modify, and test small units
- Composability: Small pieces combine flexibly
- Refactorability: Can restructure without rewriting everything

### Library-First Design

The core should be an importable Python library. Interfaces (CLI, HTTP, MCP, LSP) are wrappers around the library, ideally autogenerated from the API via introspection.

### Everything is a Plugin

Where possible, use plugin protocols instead of hardcoded implementations. Even "native" integrations should implement the same plugin interface as third-party ones.

### Maximally Useful Defaults

Every configurable option should have a default that:
- Works well for the common case (80% of users shouldn't need to configure it)
- Errs on the side of usefulness over safety-theater
- Can be discovered and changed when needed
